{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor,DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_excel(r\"E:\\results.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(['label'],axis=1)\n",
    "y=df[['label']]\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Dropout\n",
    "from keras.layers.core import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Satwik\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                72        \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 185\n",
      "Trainable params: 185\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=5, kernel_initializer='normal', activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enter_data():\n",
    "   \n",
    "    ph_val=float(input(\"enter ph data\"))\n",
    "    temp_val=float(input(\"enter temperature of soil\"))\n",
    "    humidity_val=float(input(\"enter humidity\"))\n",
    "    rainfall_val=float(input(\"enter rainfall\"))\n",
    "    moisture_val=float(input(\"enter moisture \"))\n",
    "    \n",
    "    #y_test=list((ph_val,temp_val,humidity_val,rainfall_val,moisture_val))\n",
    "    y_test= [[ph_val,temp_val,humidity_val,rainfall_val,moisture_val]]\n",
    "    \n",
    "    #print(y_test)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Satwik\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 19 samples, validate on 5 samples\n",
      "Epoch 1/150\n",
      "19/19 [==============================] - 1s 28ms/step - loss: 47.2069 - mse: 47.2069 - mae: 5.6073 - val_loss: 3.1646 - val_mse: 3.1646 - val_mae: 1.7504\n",
      "Epoch 2/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 35.2748 - mse: 35.2748 - mae: 4.7468 - val_loss: 1.6314 - val_mse: 1.6314 - val_mae: 1.2558\n",
      "Epoch 3/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 25.4228 - mse: 25.4228 - mae: 3.9287 - val_loss: 0.6918 - val_mse: 0.6918 - val_mae: 0.7745\n",
      "Epoch 4/150\n",
      "19/19 [==============================] - 0s 525us/step - loss: 17.4799 - mse: 17.4799 - mae: 3.1431 - val_loss: 0.3053 - val_mse: 0.3053 - val_mae: 0.4819\n",
      "Epoch 5/150\n",
      "19/19 [==============================] - 0s 630us/step - loss: 11.2838 - mse: 11.2838 - mae: 2.4813 - val_loss: 0.4218 - val_mse: 0.4218 - val_mae: 0.5806\n",
      "Epoch 6/150\n",
      "19/19 [==============================] - 0s 524us/step - loss: 6.7484 - mse: 6.7484 - mae: 1.9551 - val_loss: 0.9759 - val_mse: 0.9759 - val_mae: 0.6898\n",
      "Epoch 7/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 3.7477 - mse: 3.7477 - mae: 1.4756 - val_loss: 1.8770 - val_mse: 1.8770 - val_mae: 0.9485\n",
      "Epoch 8/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 2.0901 - mse: 2.0901 - mae: 1.0410 - val_loss: 2.6417 - val_mse: 2.6417 - val_mae: 1.2164\n",
      "Epoch 9/150\n",
      "19/19 [==============================] - 0s 476us/step - loss: 1.4044 - mse: 1.4044 - mae: 0.8237 - val_loss: 3.4215 - val_mse: 3.4215 - val_mae: 1.4472\n",
      "Epoch 10/150\n",
      "19/19 [==============================] - 0s 484us/step - loss: 1.5260 - mse: 1.5260 - mae: 0.8457 - val_loss: 4.1835 - val_mse: 4.1835 - val_mae: 1.6455\n",
      "Epoch 11/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 2.1998 - mse: 2.1998 - mae: 1.1997 - val_loss: 4.8687 - val_mse: 4.8687 - val_mae: 1.8078\n",
      "Epoch 12/150\n",
      "19/19 [==============================] - 0s 369us/step - loss: 3.1558 - mse: 3.1558 - mae: 1.5597 - val_loss: 5.4278 - val_mse: 5.4278 - val_mae: 1.9321\n",
      "Epoch 13/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 4.1511 - mse: 4.1511 - mae: 1.8401 - val_loss: 5.8274 - val_mse: 5.8274 - val_mae: 2.0179\n",
      "Epoch 14/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 4.9958 - mse: 4.9958 - mae: 2.0404 - val_loss: 6.0518 - val_mse: 6.0518 - val_mae: 2.0665\n",
      "Epoch 15/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 5.5652 - mse: 5.5652 - mae: 2.1628 - val_loss: 6.1025 - val_mse: 6.1025 - val_mae: 2.0803\n",
      "Epoch 16/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 5.8036 - mse: 5.8036 - mae: 2.2123 - val_loss: 5.9945 - val_mse: 5.9945 - val_mae: 2.0630\n",
      "Epoch 17/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 5.7143 - mse: 5.7143 - mae: 2.1960 - val_loss: 5.7521 - val_mse: 5.7521 - val_mae: 2.0184\n",
      "Epoch 18/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 5.3445 - mse: 5.3445 - mae: 2.1220 - val_loss: 5.4048 - val_mse: 5.4048 - val_mae: 1.9508\n",
      "Epoch 19/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 4.7683 - mse: 4.7683 - mae: 1.9994 - val_loss: 4.9835 - val_mse: 4.9835 - val_mae: 1.8647\n",
      "Epoch 20/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 4.0709 - mse: 4.0709 - mae: 1.8372 - val_loss: 4.5180 - val_mse: 4.5180 - val_mae: 1.7644\n",
      "Epoch 21/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 3.3369 - mse: 3.3369 - mae: 1.6445 - val_loss: 4.0353 - val_mse: 4.0353 - val_mae: 1.6540\n",
      "Epoch 22/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 2.6404 - mse: 2.6404 - mae: 1.4300 - val_loss: 3.5582 - val_mse: 3.5582 - val_mae: 1.5375\n",
      "Epoch 23/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 2.0388 - mse: 2.0388 - mae: 1.2025 - val_loss: 3.1051 - val_mse: 3.1051 - val_mae: 1.4186\n",
      "Epoch 24/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.5703 - mse: 1.5703 - mae: 0.9697 - val_loss: 2.6890 - val_mse: 2.6890 - val_mae: 1.3010\n",
      "Epoch 25/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 1.2519 - mse: 1.2519 - mae: 0.8005 - val_loss: 2.3188 - val_mse: 2.3188 - val_mae: 1.1877\n",
      "Epoch 26/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 1.0817 - mse: 1.0817 - mae: 0.7057 - val_loss: 1.9987 - val_mse: 1.9987 - val_mae: 1.0818\n",
      "Epoch 27/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 1.0414 - mse: 1.0414 - mae: 0.7187 - val_loss: 1.7296 - val_mse: 1.7296 - val_mae: 0.9854\n",
      "Epoch 28/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.1011 - mse: 1.1011 - mae: 0.7523 - val_loss: 1.5096 - val_mse: 1.5096 - val_mae: 0.9007\n",
      "Epoch 29/150\n",
      "19/19 [==============================] - 0s 525us/step - loss: 1.2241 - mse: 1.2241 - mae: 0.7904 - val_loss: 1.3351 - val_mse: 1.3351 - val_mae: 0.8291\n",
      "Epoch 30/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.3731 - mse: 1.3731 - mae: 0.8425 - val_loss: 1.2014 - val_mse: 1.2014 - val_mae: 0.7757\n",
      "Epoch 31/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 1.5140 - mse: 1.5140 - mae: 0.8885 - val_loss: 1.1035 - val_mse: 1.1035 - val_mae: 0.7441\n",
      "Epoch 32/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.6205 - mse: 1.6205 - mae: 0.9260 - val_loss: 1.0369 - val_mse: 1.0369 - val_mae: 0.7219\n",
      "Epoch 33/150\n",
      "19/19 [==============================] - 0s 474us/step - loss: 1.6755 - mse: 1.6755 - mae: 0.9443 - val_loss: 0.9975 - val_mse: 0.9975 - val_mae: 0.7086\n",
      "Epoch 34/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.6724 - mse: 1.6724 - mae: 0.9442 - val_loss: 0.9817 - val_mse: 0.9817 - val_mae: 0.7037\n",
      "Epoch 35/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.6137 - mse: 1.6137 - mae: 0.9265 - val_loss: 0.9866 - val_mse: 0.9866 - val_mae: 0.7062\n",
      "Epoch 36/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 1.5095 - mse: 1.5095 - mae: 0.8937 - val_loss: 1.0096 - val_mse: 1.0096 - val_mae: 0.7150\n",
      "Epoch 37/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.3747 - mse: 1.3747 - mae: 0.8489 - val_loss: 1.0482 - val_mse: 1.0482 - val_mae: 0.7330\n",
      "Epoch 38/150\n",
      "19/19 [==============================] - 0s 473us/step - loss: 1.2265 - mse: 1.2265 - mae: 0.8019 - val_loss: 1.0996 - val_mse: 1.0996 - val_mae: 0.7645\n",
      "Epoch 39/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 1.0814 - mse: 1.0814 - mae: 0.7510 - val_loss: 1.1609 - val_mse: 1.1609 - val_mae: 0.7998\n",
      "Epoch 40/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.9532 - mse: 0.9532 - mae: 0.7057 - val_loss: 1.2283 - val_mse: 1.2283 - val_mae: 0.8367\n",
      "Epoch 41/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.8515 - mse: 0.8515 - mae: 0.6728 - val_loss: 1.2981 - val_mse: 1.2981 - val_mae: 0.8734\n",
      "Epoch 42/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7812 - mse: 0.7812 - mae: 0.6409 - val_loss: 1.3660 - val_mse: 1.3660 - val_mae: 0.9080\n",
      "Epoch 43/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 0.7419 - mse: 0.7419 - mae: 0.6134 - val_loss: 1.4276 - val_mse: 1.4276 - val_mae: 0.9389\n",
      "Epoch 44/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7294 - mse: 0.7294 - mae: 0.5981 - val_loss: 1.4790 - val_mse: 1.4790 - val_mae: 0.9648\n",
      "Epoch 45/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.7364 - mse: 0.7364 - mae: 0.6086 - val_loss: 1.5168 - val_mse: 1.5168 - val_mae: 0.9846\n",
      "Epoch 46/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7540 - mse: 0.7540 - mae: 0.6304 - val_loss: 1.5382 - val_mse: 1.5382 - val_mae: 0.9974\n",
      "Epoch 47/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.7737 - mse: 0.7737 - mae: 0.6551 - val_loss: 1.5418 - val_mse: 1.5418 - val_mae: 1.0030\n",
      "Epoch 48/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7879 - mse: 0.7879 - mae: 0.6711 - val_loss: 1.5271 - val_mse: 1.5271 - val_mae: 1.0012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.7916 - mse: 0.7916 - mae: 0.6785 - val_loss: 1.4949 - val_mse: 1.4949 - val_mae: 0.9922\n",
      "Epoch 50/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.7821 - mse: 0.7821 - mae: 0.6775 - val_loss: 1.4468 - val_mse: 1.4468 - val_mae: 0.9765\n",
      "Epoch 51/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7597 - mse: 0.7597 - mae: 0.6686 - val_loss: 1.3854 - val_mse: 1.3854 - val_mae: 0.9548\n",
      "Epoch 52/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.7266 - mse: 0.7266 - mae: 0.6526 - val_loss: 1.3137 - val_mse: 1.3137 - val_mae: 0.9280\n",
      "Epoch 53/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.6866 - mse: 0.6866 - mae: 0.6307 - val_loss: 1.2353 - val_mse: 1.2353 - val_mae: 0.8974\n",
      "Epoch 54/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.6441 - mse: 0.6441 - mae: 0.6041 - val_loss: 1.1533 - val_mse: 1.1533 - val_mae: 0.8639\n",
      "Epoch 55/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.6033 - mse: 0.6033 - mae: 0.5743 - val_loss: 1.0709 - val_mse: 1.0709 - val_mae: 0.8288\n",
      "Epoch 56/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.5675 - mse: 0.5675 - mae: 0.5502 - val_loss: 0.9908 - val_mse: 0.9908 - val_mae: 0.7932\n",
      "Epoch 57/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.5388 - mse: 0.5388 - mae: 0.5309 - val_loss: 0.9152 - val_mse: 0.9152 - val_mae: 0.7583\n",
      "Epoch 58/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.5179 - mse: 0.5179 - mae: 0.5175 - val_loss: 0.8457 - val_mse: 0.8457 - val_mae: 0.7249\n",
      "Epoch 59/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.5040 - mse: 0.5040 - mae: 0.5118 - val_loss: 0.7834 - val_mse: 0.7834 - val_mae: 0.6940\n",
      "Epoch 60/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.4958 - mse: 0.4958 - mae: 0.5164 - val_loss: 0.7287 - val_mse: 0.7287 - val_mae: 0.6662\n",
      "Epoch 61/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.4909 - mse: 0.4909 - mae: 0.5195 - val_loss: 0.6820 - val_mse: 0.6820 - val_mae: 0.6419\n",
      "Epoch 62/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.4872 - mse: 0.4872 - mae: 0.5207 - val_loss: 0.6431 - val_mse: 0.6431 - val_mae: 0.6216\n",
      "Epoch 63/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.4825 - mse: 0.4825 - mae: 0.5198 - val_loss: 0.6114 - val_mse: 0.6114 - val_mae: 0.6052\n",
      "Epoch 64/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.4754 - mse: 0.4754 - mae: 0.5169 - val_loss: 0.5863 - val_mse: 0.5863 - val_mae: 0.5927\n",
      "Epoch 65/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 0.4652 - mse: 0.4652 - mae: 0.5118 - val_loss: 0.5671 - val_mse: 0.5671 - val_mae: 0.5838\n",
      "Epoch 66/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.4520 - mse: 0.4520 - mae: 0.5049 - val_loss: 0.5530 - val_mse: 0.5530 - val_mae: 0.5781\n",
      "Epoch 67/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.4365 - mse: 0.4365 - mae: 0.4963 - val_loss: 0.5429 - val_mse: 0.5429 - val_mae: 0.5751\n",
      "Epoch 68/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.4196 - mse: 0.4196 - mae: 0.4863 - val_loss: 0.5353 - val_mse: 0.5353 - val_mae: 0.5730\n",
      "Epoch 69/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.4024 - mse: 0.4024 - mae: 0.4752 - val_loss: 0.5293 - val_mse: 0.5293 - val_mae: 0.5710\n",
      "Epoch 70/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.3862 - mse: 0.3862 - mae: 0.4634 - val_loss: 0.5244 - val_mse: 0.5244 - val_mae: 0.5695\n",
      "Epoch 71/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.3716 - mse: 0.3716 - mae: 0.4513 - val_loss: 0.5198 - val_mse: 0.5198 - val_mae: 0.5682\n",
      "Epoch 72/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.3592 - mse: 0.3592 - mae: 0.4425 - val_loss: 0.5144 - val_mse: 0.5144 - val_mae: 0.5654\n",
      "Epoch 73/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3488 - mse: 0.3488 - mae: 0.4378 - val_loss: 0.5076 - val_mse: 0.5076 - val_mae: 0.5611\n",
      "Epoch 74/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3401 - mse: 0.3401 - mae: 0.4351 - val_loss: 0.4991 - val_mse: 0.4991 - val_mae: 0.5556\n",
      "Epoch 75/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3328 - mse: 0.3328 - mae: 0.4321 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5488\n",
      "Epoch 76/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.3254 - mse: 0.3254 - mae: 0.4264 - val_loss: 0.4758 - val_mse: 0.4758 - val_mae: 0.5405\n",
      "Epoch 77/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3202 - mse: 0.3202 - mae: 0.4237 - val_loss: 0.4612 - val_mse: 0.4612 - val_mae: 0.5308\n",
      "Epoch 78/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.3178 - mse: 0.3178 - mae: 0.4239 - val_loss: 0.4452 - val_mse: 0.4452 - val_mae: 0.5200\n",
      "Epoch 79/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.3148 - mse: 0.3148 - mae: 0.4231 - val_loss: 0.4284 - val_mse: 0.4284 - val_mae: 0.5084\n",
      "Epoch 80/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3115 - mse: 0.3115 - mae: 0.4216 - val_loss: 0.4113 - val_mse: 0.4113 - val_mae: 0.4964\n",
      "Epoch 81/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.3082 - mse: 0.3082 - mae: 0.4196 - val_loss: 0.3943 - val_mse: 0.3943 - val_mae: 0.4843\n",
      "Epoch 82/150\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 0.3050 - mse: 0.3050 - mae: 0.4183 - val_loss: 0.3780 - val_mse: 0.3780 - val_mae: 0.4723\n",
      "Epoch 83/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.3021 - mse: 0.3021 - mae: 0.4185 - val_loss: 0.3627 - val_mse: 0.3627 - val_mae: 0.4607\n",
      "Epoch 84/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2995 - mse: 0.2995 - mae: 0.4183 - val_loss: 0.3485 - val_mse: 0.3485 - val_mae: 0.4498\n",
      "Epoch 85/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2971 - mse: 0.2971 - mae: 0.4182 - val_loss: 0.3358 - val_mse: 0.3358 - val_mae: 0.4398\n",
      "Epoch 86/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2949 - mse: 0.2949 - mae: 0.4196 - val_loss: 0.3246 - val_mse: 0.3246 - val_mae: 0.4309\n",
      "Epoch 87/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2926 - mse: 0.2926 - mae: 0.4203 - val_loss: 0.3150 - val_mse: 0.3150 - val_mae: 0.4231\n",
      "Epoch 88/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2903 - mse: 0.2903 - mae: 0.4202 - val_loss: 0.3070 - val_mse: 0.3070 - val_mae: 0.4164\n",
      "Epoch 89/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2877 - mse: 0.2877 - mae: 0.4192 - val_loss: 0.3006 - val_mse: 0.3006 - val_mae: 0.4110\n",
      "Epoch 90/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2849 - mse: 0.2849 - mae: 0.4175 - val_loss: 0.2956 - val_mse: 0.2956 - val_mae: 0.4067\n",
      "Epoch 91/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2817 - mse: 0.2817 - mae: 0.4151 - val_loss: 0.2919 - val_mse: 0.2919 - val_mae: 0.4036\n",
      "Epoch 92/150\n",
      "19/19 [==============================] - 0s 469us/step - loss: 0.2783 - mse: 0.2783 - mae: 0.4119 - val_loss: 0.2894 - val_mse: 0.2894 - val_mae: 0.4014\n",
      "Epoch 93/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2745 - mse: 0.2745 - mae: 0.4082 - val_loss: 0.2879 - val_mse: 0.2879 - val_mae: 0.4001\n",
      "Epoch 94/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2706 - mse: 0.2706 - mae: 0.4039 - val_loss: 0.2872 - val_mse: 0.2872 - val_mae: 0.3994\n",
      "Epoch 95/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2666 - mse: 0.2666 - mae: 0.3992 - val_loss: 0.2871 - val_mse: 0.2871 - val_mae: 0.3993\n",
      "Epoch 96/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2625 - mse: 0.2625 - mae: 0.3941 - val_loss: 0.2874 - val_mse: 0.2874 - val_mae: 0.3995\n",
      "Epoch 97/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2585 - mse: 0.2585 - mae: 0.3892 - val_loss: 0.2879 - val_mse: 0.2879 - val_mae: 0.3999\n",
      "Epoch 98/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2545 - mse: 0.2545 - mae: 0.3851 - val_loss: 0.2884 - val_mse: 0.2884 - val_mae: 0.4003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 99/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.2507 - mse: 0.2507 - mae: 0.3810 - val_loss: 0.2888 - val_mse: 0.2888 - val_mae: 0.4006\n",
      "Epoch 100/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2470 - mse: 0.2470 - mae: 0.3768 - val_loss: 0.2889 - val_mse: 0.2889 - val_mae: 0.4007\n",
      "Epoch 101/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.2434 - mse: 0.2434 - mae: 0.3727 - val_loss: 0.2885 - val_mse: 0.2885 - val_mae: 0.4003\n",
      "Epoch 102/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.2399 - mse: 0.2399 - mae: 0.3693 - val_loss: 0.2876 - val_mse: 0.2876 - val_mae: 0.3995\n",
      "Epoch 103/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2375 - mse: 0.2375 - mae: 0.3672 - val_loss: 0.2861 - val_mse: 0.2861 - val_mae: 0.3982\n",
      "Epoch 104/150\n",
      "19/19 [==============================] - 0s 366us/step - loss: 0.2365 - mse: 0.2365 - mae: 0.3665 - val_loss: 0.2842 - val_mse: 0.2842 - val_mae: 0.3965\n",
      "Epoch 105/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2354 - mse: 0.2354 - mae: 0.3658 - val_loss: 0.2817 - val_mse: 0.2817 - val_mae: 0.3944\n",
      "Epoch 106/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2337 - mse: 0.2337 - mae: 0.3650 - val_loss: 0.2789 - val_mse: 0.2789 - val_mae: 0.3919\n",
      "Epoch 107/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2315 - mse: 0.2315 - mae: 0.3637 - val_loss: 0.2756 - val_mse: 0.2756 - val_mae: 0.3890\n",
      "Epoch 108/150\n",
      "19/19 [==============================] - 0s 472us/step - loss: 0.2289 - mse: 0.2289 - mae: 0.3620 - val_loss: 0.2718 - val_mse: 0.2718 - val_mae: 0.3857\n",
      "Epoch 109/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2259 - mse: 0.2259 - mae: 0.3599 - val_loss: 0.2676 - val_mse: 0.2676 - val_mae: 0.3820\n",
      "Epoch 110/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.2226 - mse: 0.2226 - mae: 0.3578 - val_loss: 0.2630 - val_mse: 0.2630 - val_mae: 0.3778\n",
      "Epoch 111/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2194 - mse: 0.2194 - mae: 0.3559 - val_loss: 0.2579 - val_mse: 0.2579 - val_mae: 0.3732\n",
      "Epoch 112/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.2171 - mse: 0.2171 - mae: 0.3547 - val_loss: 0.2524 - val_mse: 0.2524 - val_mae: 0.3682\n",
      "Epoch 113/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.2150 - mse: 0.2150 - mae: 0.3537 - val_loss: 0.2467 - val_mse: 0.2467 - val_mae: 0.3628\n",
      "Epoch 114/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2130 - mse: 0.2130 - mae: 0.3527 - val_loss: 0.2407 - val_mse: 0.2407 - val_mae: 0.3577\n",
      "Epoch 115/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2110 - mse: 0.2110 - mae: 0.3514 - val_loss: 0.2348 - val_mse: 0.2348 - val_mae: 0.3533\n",
      "Epoch 116/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2088 - mse: 0.2088 - mae: 0.3498 - val_loss: 0.2290 - val_mse: 0.2290 - val_mae: 0.3490\n",
      "Epoch 117/150\n",
      "19/19 [==============================] - 0s 368us/step - loss: 0.2066 - mse: 0.2066 - mae: 0.3480 - val_loss: 0.2233 - val_mse: 0.2233 - val_mae: 0.3448\n",
      "Epoch 118/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2043 - mse: 0.2043 - mae: 0.3460 - val_loss: 0.2179 - val_mse: 0.2179 - val_mae: 0.3407\n",
      "Epoch 119/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.2020 - mse: 0.2020 - mae: 0.3439 - val_loss: 0.2128 - val_mse: 0.2128 - val_mae: 0.3368\n",
      "Epoch 120/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1996 - mse: 0.1996 - mae: 0.3416 - val_loss: 0.2081 - val_mse: 0.2081 - val_mae: 0.3333\n",
      "Epoch 121/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1976 - mse: 0.1976 - mae: 0.3396 - val_loss: 0.2039 - val_mse: 0.2039 - val_mae: 0.3303\n",
      "Epoch 122/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1957 - mse: 0.1957 - mae: 0.3378 - val_loss: 0.2000 - val_mse: 0.2000 - val_mae: 0.3276\n",
      "Epoch 123/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1938 - mse: 0.1938 - mae: 0.3363 - val_loss: 0.1967 - val_mse: 0.1967 - val_mae: 0.3251\n",
      "Epoch 124/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1921 - mse: 0.1921 - mae: 0.3350 - val_loss: 0.1937 - val_mse: 0.1937 - val_mae: 0.3228\n",
      "Epoch 125/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1903 - mse: 0.1903 - mae: 0.3339 - val_loss: 0.1912 - val_mse: 0.1912 - val_mae: 0.3207\n",
      "Epoch 126/150\n",
      "19/19 [==============================] - 0s 419us/step - loss: 0.1882 - mse: 0.1882 - mae: 0.3325 - val_loss: 0.1889 - val_mse: 0.1889 - val_mae: 0.3187\n",
      "Epoch 127/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1861 - mse: 0.1861 - mae: 0.3312 - val_loss: 0.1868 - val_mse: 0.1868 - val_mae: 0.3168\n",
      "Epoch 128/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1841 - mse: 0.1841 - mae: 0.3299 - val_loss: 0.1848 - val_mse: 0.1848 - val_mae: 0.3151\n",
      "Epoch 129/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1822 - mse: 0.1822 - mae: 0.3289 - val_loss: 0.1829 - val_mse: 0.1829 - val_mae: 0.3133\n",
      "Epoch 130/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1803 - mse: 0.1803 - mae: 0.3278 - val_loss: 0.1810 - val_mse: 0.1810 - val_mae: 0.3115\n",
      "Epoch 131/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1785 - mse: 0.1785 - mae: 0.3268 - val_loss: 0.1789 - val_mse: 0.1789 - val_mae: 0.3097\n",
      "Epoch 132/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1769 - mse: 0.1769 - mae: 0.3258 - val_loss: 0.1768 - val_mse: 0.1768 - val_mae: 0.3078\n",
      "Epoch 133/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.1752 - mse: 0.1752 - mae: 0.3247 - val_loss: 0.1745 - val_mse: 0.1745 - val_mae: 0.3059\n",
      "Epoch 134/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1735 - mse: 0.1735 - mae: 0.3234 - val_loss: 0.1721 - val_mse: 0.1721 - val_mae: 0.3039\n",
      "Epoch 135/150\n",
      "19/19 [==============================] - 0s 369us/step - loss: 0.1717 - mse: 0.1717 - mae: 0.3220 - val_loss: 0.1695 - val_mse: 0.1695 - val_mae: 0.3018\n",
      "Epoch 136/150\n",
      "19/19 [==============================] - 0s 315us/step - loss: 0.1700 - mse: 0.1700 - mae: 0.3206 - val_loss: 0.1667 - val_mse: 0.1667 - val_mae: 0.2995\n",
      "Epoch 137/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1684 - mse: 0.1684 - mae: 0.3193 - val_loss: 0.1639 - val_mse: 0.1639 - val_mae: 0.2971\n",
      "Epoch 138/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1668 - mse: 0.1668 - mae: 0.3180 - val_loss: 0.1610 - val_mse: 0.1610 - val_mae: 0.2945\n",
      "Epoch 139/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1652 - mse: 0.1652 - mae: 0.3167 - val_loss: 0.1580 - val_mse: 0.1580 - val_mae: 0.2919\n",
      "Epoch 140/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1636 - mse: 0.1636 - mae: 0.3154 - val_loss: 0.1550 - val_mse: 0.1550 - val_mae: 0.2891\n",
      "Epoch 141/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1620 - mse: 0.1620 - mae: 0.3141 - val_loss: 0.1520 - val_mse: 0.1520 - val_mae: 0.2864\n",
      "Epoch 142/150\n",
      "19/19 [==============================] - 0s 389us/step - loss: 0.1605 - mse: 0.1605 - mae: 0.3128 - val_loss: 0.1490 - val_mse: 0.1490 - val_mae: 0.2835\n",
      "Epoch 143/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1589 - mse: 0.1589 - mae: 0.3115 - val_loss: 0.1460 - val_mse: 0.1460 - val_mae: 0.2807\n",
      "Epoch 144/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1574 - mse: 0.1574 - mae: 0.3102 - val_loss: 0.1431 - val_mse: 0.1431 - val_mae: 0.2779\n",
      "Epoch 145/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1559 - mse: 0.1559 - mae: 0.3090 - val_loss: 0.1403 - val_mse: 0.1403 - val_mae: 0.2751\n",
      "Epoch 146/150\n",
      "19/19 [==============================] - 0s 420us/step - loss: 0.1544 - mse: 0.1544 - mae: 0.3077 - val_loss: 0.1375 - val_mse: 0.1375 - val_mae: 0.2723\n",
      "Epoch 147/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1529 - mse: 0.1529 - mae: 0.3065 - val_loss: 0.1349 - val_mse: 0.1349 - val_mae: 0.2696\n",
      "Epoch 148/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1514 - mse: 0.1514 - mae: 0.3053 - val_loss: 0.1323 - val_mse: 0.1323 - val_mae: 0.2669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1500 - mse: 0.1500 - mae: 0.3042 - val_loss: 0.1298 - val_mse: 0.1298 - val_mae: 0.2644\n",
      "Epoch 150/150\n",
      "19/19 [==============================] - 0s 367us/step - loss: 0.1486 - mse: 0.1486 - mae: 0.3029 - val_loss: 0.1274 - val_mse: 0.1274 - val_mae: 0.2620\n"
     ]
    }
   ],
   "source": [
    "crop_pred= model.fit(x_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(value):\n",
    "     for i in value:\n",
    "        if i<=1.5:\n",
    "            print(\"paddy\")\n",
    "        elif i<=2.5:\n",
    "            print(\"corn\")\n",
    "        elif i<=3.5:\n",
    "            print(\"potato\")\n",
    "        elif i<=4.5:\n",
    "            print(\"tomato\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('crop.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.9251007],\n",
       "       [3.3704836],\n",
       "       [1.3198069],\n",
       "       [3.2845442],\n",
       "       [3.788895 ],\n",
       "       [3.443825 ],\n",
       "       [3.8373463],\n",
       "       [3.700764 ],\n",
       "       [1.7833174],\n",
       "       [1.8472012],\n",
       "       [3.6043055]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter ph data0\n",
      "enter temperature of soil0\n",
      "enter humidity0\n",
      "enter rainfall0\n",
      "enter moisture 0\n"
     ]
    }
   ],
   "source": [
    "y=enter_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
